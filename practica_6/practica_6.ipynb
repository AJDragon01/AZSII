{"cells":[{"cell_type":"markdown","metadata":{"id":"FKl06fC8MqgR"},"source":["# Практическая работа №6\n","\n","# Выполнил студент группы ББМО-01-23 Егоров Ю.А.\n","\n","\n","##Загрузка и создание двух различных моделей"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34XnahwANZqA","executionInfo":{"status":"ok","timestamp":1734868343735,"user_tz":-180,"elapsed":27895,"user":{"displayName":"Юрий Егоров","userId":"01218446624262178326"}},"outputId":"21ecfc03-93f2-4f19-a0b1-bd5028422832"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gt1lcHHdM2Qq","outputId":"f48af644-d8e6-401d-c38a-e6cbe39033b9","executionInfo":{"status":"ok","timestamp":1734868505507,"user_tz":-180,"elapsed":59433,"user":{"displayName":"Юрий Егоров","userId":"01218446624262178326"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.4308\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1225\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0796\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0558\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0409\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2964\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0513\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0312\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0198\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0146\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","# Загрузка данных MNIST\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","#  Нормализация данных\n","train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","# Преобразование меток в one-hot encoding\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","#  Модель 1: Простая полносвязная нейронная сеть\n","model1 = Sequential([\n","  Flatten(input_shape=(28, 28)),\n","  Dense(128, activation='relu'),\n","  Dense(10, activation='softmax')])\n","#   Компиляция модели\n","model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n","#   Обучение модели\n","model1.fit(train_images, train_labels, epochs=5)\n","#   Сохранение модели\n","model1.save('/content/drive/MyDrive/aziis/practica_6/mnist_model1.h5')\n","#   Модель 2: Свёрточная нейронная сеть (CNN)\n","model2 = Sequential([\n","  Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","  MaxPooling2D((2, 2)),\n","  Flatten(),\n","  Dense(128, activation='relu'),\n","  Dense(10, activation='softmax')\n","])\n","# Компиляция модели\n","model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n","#  Обучение модели\n","model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n","# Сохранение модели\n","model2.save('/content/drive/MyDrive/aziis/practica_6/mnist_model2.h5')"]},{"cell_type":"markdown","metadata":{"id":"jJsiCu2_NCS_"},"source":["##Реализация атаки FGSM на первую модель"]},{"cell_type":"code","source":["import numpy as np\n","# Функция для реализации FGSM атаки\n","def fgsm_attack(image, epsilon, gradient):\n","  # Применение знака градиента к изображению\n","  perturbed_image = image + epsilon * np.sign(gradient)\n","  # Обрезка значений, чтобы они оставались в пределах [0,1]\n","  perturbed_image = np.clip(perturbed_image, 0, 1)\n","  return perturbed_image\n","# Вычисление градиента\n","def generate_adversarial_example(model, image, label, epsilon):\n","    #  Превращаем изображение в формат, подходящий для модели\n","    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n","\n","    # Если label — это one-hot вектор, преобразуем его в индекс\n","    if len(label.shape) > 1 and label.shape[1] > 1:\n","        label = np.argmax(label)\n","    label = tf.convert_to_tensor(label)\n","\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n","\n","    gradient = tape.gradient(loss, image)\n","\n","    # Применяем FGSM\n","    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n","\n","    #  Убедимся, что adversarial_image имеет правильную форму\n","    return np.reshape(adversarial_image, (28, 28, 1))\n","\n","def generate_adversarial_dataset(model, images, labels, epsilon):\n","    adversarial_images = []\n","    for i in range(len(images)):\n","        adv_image = generate_adversarial_example(model, images[i], labels[i], epsilon)\n","        adversarial_images.append(adv_image.reshape(28, 28))\n","\n","    adversarial_images = np.array(adversarial_images)\n","\n","    # Проверка формы\n","    print(\"Shape of adversarial_images:\", adversarial_images.shape)\n","\n","    return adversarial_images\n","\n","\n","# Генерация противоречивых примеров для первой модели\n","epsilon = 0.1\n","adversarial_images_model1 = generate_adversarial_dataset(model1, test_images, test_labels, epsilon)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLuiTyrdd_1I","outputId":"05910ead-389f-4441-839e-99240dacbebd","executionInfo":{"status":"ok","timestamp":1734868609577,"user_tz":-180,"elapsed":97880,"user":{"displayName":"Юрий Егоров","userId":"01218446624262178326"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of adversarial_images: (10000, 28, 28)\n"]}]},{"cell_type":"markdown","source":["## Оценка противоречивых примеров на обеих моделях"],"metadata":{"id":"3i9N-vKjqBRj"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySy0YHHJNWwo","outputId":"7654c2f1-08da-430a-9e03-bc44eb3a046e","executionInfo":{"status":"ok","timestamp":1734868716369,"user_tz":-180,"elapsed":3505,"user":{"displayName":"Юрий Егоров","userId":"01218446624262178326"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0995 - loss: 6.4203\n","Accuracy of model1 on adversarial examples: 0.12759999930858612\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1759\n","Accuracy of model2 on adversarial examples from model1: 0.9562000036239624\n"]}],"source":["# Оценка первой модели на противоречивых примерах\n","loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n","print(f'Accuracy of model1 on adversarial examples: {acc1}')\n","\n","# Оценка второй модели на противоречивых примерах (перенос атаки)\n","adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n","loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n","print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"]},{"cell_type":"markdown","metadata":{"id":"6Akot1nnZck6"},"source":["## Анализ переносимости атак"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"LGP6uDGAZvJX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b35822aa-5c2b-4e35-b13b-14713e257131","executionInfo":{"status":"ok","timestamp":1734868845546,"user_tz":-180,"elapsed":126457,"user":{"displayName":"Юрий Егоров","userId":"01218446624262178326"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of adversarial_images: (10000, 28, 28)\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9040 - loss: 0.2927\n","Accuracy of model1 on adversarial examples from model2: 0.9258999824523926\n"]}],"source":["adversarial_images_model2 = generate_adversarial_dataset(model2,\n","test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n","\n","# Оценка первой модели на противоречивых примерах второй модели\n","loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28,\n","28), test_labels)\n","print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"]},{"cell_type":"markdown","source":["#Вывод:\n","В ходе выполнения работы было проведено исследование воздействия атаки по переносу, при которой противоречивые примеры, сгенерированные для одной модели, использовались для тестирования другой. Для реализации атак применялся метод FGSM (Fast Gradient Sign Method), позволяющий быстро создавать искажённые примеры, способные повлиять на предсказания моделей.\n","\n","Результаты эксперимента показали следующее:\n","\n","- Модель 1, на которой были сгенерированы противоречивые примеры, продемонстрировала значительное снижение точности: с 98% до ~10% (точная точность 0.1276). Это свидетельствует о её высокой уязвимости к прямым FGSM-атакам.\n","- Модель 2, протестированная на противоречивых примерах, созданных для модели 1, показала существенно меньший эффект. Её точность снизилась незначительно, с ~95% до ~94.6% (точная точность 0.9562), что указывает на её устойчивость к переносу атак.\n","\n","Дополнительно были проведены эксперименты с противоречивыми примерами, созданными для модели 2:\n","\n","- Модель 1, протестированная на этих примерах, показала небольшое снижение точности до ~90.4% (точная точность 0.9259). Это падение остаётся значительно меньшим, чем при атаке собственных примеров модели 1.\n","\n","Таким образом, результаты эксперимента демонстрируют:\n","\n","- Прямые FGSM-атаки существенно снижают точность модели, для которой генерировались примеры (как в случае модели 1).\n","- Перенос атак на другую модель менее эффективен, особенно если эта модель изначально устойчива к FGSM (как в случае модели 2).\n","- Устойчивость моделей к переносу атак, даже при небольшом снижении точности, подчёркивает важность разработки методов, направленных на повышение их защищённости.\n","\n","Эти выводы подтверждают необходимость создания моделей, обладающих устойчивостью как к прямым атакам, так и к атакам, перенесённым с других моделей."],"metadata":{"id":"cq9s_3FMEsj3"}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}